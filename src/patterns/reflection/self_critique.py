"""
Reflection Pattern: è‡ªæˆ‘æ‰¹è©•èˆ‡æ”¹é€²æ©Ÿåˆ¶

åŸºæ–¼ First Principles çš„åæ€è¨­è¨ˆï¼š
1. è‡ªæˆ‘è©•ä¼°ï¼šAgent èƒ½å¤ è©•ä¼°è‡ªå·±çš„è¼¸å‡ºå“è³ª
2. ç¼ºé™·è­˜åˆ¥ï¼šè‡ªå‹•ç™¼ç¾è¼¸å‡ºä¸­çš„å•é¡Œå’Œä¸è¶³
3. è¿­ä»£æ”¹é€²ï¼šåŸºæ–¼æ‰¹è©•é€²è¡ŒæŒçºŒå„ªåŒ–

åƒè€ƒæ–‡æª”: docs/patterns/reflection.md
"""

from typing import Dict, List, Any, Optional, Callable, Union
from dataclasses import dataclass, field
from enum import Enum
from abc import ABC, abstractmethod
import json
import re
from datetime import datetime

from crewai import Agent, Task
from pydantic import BaseModel, Field

from ...core.agents.agent_base import BaseAgent
from ...core.tasks.task_base import BaseTask


class CritiqueAspect(Enum):
    """æ‰¹è©•ç¶­åº¦"""
    ACCURACY = "accuracy"           # æº–ç¢ºæ€§
    COMPLETENESS = "completeness"   # å®Œæ•´æ€§
    CLARITY = "clarity"             # æ¸…æ™°åº¦
    RELEVANCE = "relevance"         # ç›¸é—œæ€§
    COHERENCE = "coherence"         # é€£è²«æ€§
    DEPTH = "depth"                 # æ·±åº¦
    CREATIVITY = "creativity"       # å‰µæ„æ€§
    PRACTICALITY = "practicality"   # å¯¦ç”¨æ€§


class ReflectionLevel(Enum):
    """åæ€å±¤ç´š"""
    SURFACE = "surface"       # è¡¨é¢åæ€ï¼šåŸºæœ¬éŒ¯èª¤æª¢æŸ¥
    STRUCTURAL = "structural" # çµæ§‹åæ€ï¼šé‚è¼¯å’Œçµ„ç¹”
    DEEP = "deep"            # æ·±åº¦åæ€ï¼šæ¦‚å¿µå’Œæ´å¯Ÿ
    META = "meta"            # å…ƒåæ€ï¼šåæ€éç¨‹æœ¬èº«


@dataclass
class CritiquePoint:
    """æ‰¹è©•è¦é»"""
    aspect: CritiqueAspect
    severity: float = 0.0  # 0-1, 1è¡¨ç¤ºæœ€åš´é‡
    description: str = ""
    suggestion: str = ""
    evidence: str = ""
    location: Optional[str] = None  # å•é¡Œä½ç½®
    
    @property
    def is_critical(self) -> bool:
        return self.severity >= 0.8
    
    @property
    def is_major(self) -> bool:
        return self.severity >= 0.5
    
    @property
    def is_minor(self) -> bool:
        return self.severity < 0.3


@dataclass
class ReflectionResult:
    """åæ€çµæœ"""
    original_content: str
    critique_points: List[CritiquePoint] = field(default_factory=list)
    overall_score: float = 0.0
    reflection_level: ReflectionLevel = ReflectionLevel.SURFACE
    improvement_suggestions: List[str] = field(default_factory=list)
    revised_content: Optional[str] = None
    reflection_time: float = 0.0
    iteration_count: int = 0
    
    @property
    def needs_revision(self) -> bool:
        """æ˜¯å¦éœ€è¦ä¿®è¨‚"""
        return (self.overall_score < 0.7 or 
                any(point.is_critical for point in self.critique_points))
    
    @property
    def critical_issues_count(self) -> int:
        return sum(1 for point in self.critique_points if point.is_critical)
    
    @property
    def major_issues_count(self) -> int:
        return sum(1 for point in self.critique_points if point.is_major)


class CritiqueStrategy(ABC):
    """æ‰¹è©•ç­–ç•¥æŠ½è±¡åŸºé¡"""
    
    @abstractmethod
    def critique(self, content: str, context: Dict[str, Any]) -> List[CritiquePoint]:
        """åŸ·è¡Œæ‰¹è©•åˆ†æ"""
        pass
    
    @abstractmethod
    def get_supported_aspects(self) -> List[CritiqueAspect]:
        """ç²å–æ”¯æ´çš„æ‰¹è©•ç¶­åº¦"""
        pass


class AccuracyCritiqueStrategy(CritiqueStrategy):
    """æº–ç¢ºæ€§æ‰¹è©•ç­–ç•¥"""
    
    def critique(self, content: str, context: Dict[str, Any]) -> List[CritiquePoint]:
        """æª¢æŸ¥å…§å®¹æº–ç¢ºæ€§"""
        critique_points = []
        
        # æª¢æŸ¥æ•¸æ“šæº–ç¢ºæ€§
        critique_points.extend(self._check_factual_accuracy(content, context))
        
        # æª¢æŸ¥å¼•ç”¨å’Œä¾†æº
        critique_points.extend(self._check_citations(content))
        
        # æª¢æŸ¥æ•¸å­—å’Œçµ±è¨ˆ
        critique_points.extend(self._check_numerical_accuracy(content))
        
        return critique_points
    
    def _check_factual_accuracy(self, content: str, context: Dict[str, Any]) -> List[CritiquePoint]:
        """æª¢æŸ¥äº‹å¯¦æº–ç¢ºæ€§"""
        points = []
        
        # æŸ¥æ‰¾å¯èƒ½çš„äº‹å¯¦é™³è¿°
        fact_patterns = [
            r'\d{4}å¹´.*?ç™¼ç”Ÿ',  # æ™‚é–“ç›¸é—œäº‹å¯¦
            r'æ ¹æ“š.*?ç ”ç©¶',      # ç ”ç©¶å¼•ç”¨
            r'çµ±è¨ˆé¡¯ç¤º.*?',      # çµ±è¨ˆæ•¸æ“š
            r'å°ˆå®¶.*?è¡¨ç¤º',      # å°ˆå®¶æ„è¦‹
        ]
        
        for pattern in fact_patterns:
            matches = re.finditer(pattern, content)
            for match in matches:
                # é€™è£¡å¯ä»¥æ•´åˆäº‹å¯¦æª¢æŸ¥ API
                fact_statement = match.group()
                confidence = self._assess_fact_confidence(fact_statement, context)
                
                if confidence < 0.6:
                    points.append(CritiquePoint(
                        aspect=CritiqueAspect.ACCURACY,
                        severity=1.0 - confidence,
                        description=f"äº‹å¯¦é™³è¿°å¯ä¿¡åº¦è¼ƒä½: {fact_statement}",
                        suggestion="è«‹æä¾›å¯é ä¾†æºæˆ–é‡æ–°é©—è­‰æ­¤ä¿¡æ¯",
                        evidence=fact_statement,
                        location=f"ä½ç½® {match.start()}-{match.end()}"
                    ))
        
        return points
    
    def _check_citations(self, content: str) -> List[CritiquePoint]:
        """æª¢æŸ¥å¼•ç”¨æ ¼å¼"""
        points = []
        
        # æŸ¥æ‰¾ç¼ºå°‘å¼•ç”¨çš„è²æ˜
        claim_patterns = [
            r'ç ”ç©¶è¡¨æ˜',
            r'æ•¸æ“šé¡¯ç¤º',
            r'æ ¹æ“š.*?',
            r'å°ˆå®¶èªç‚º',
        ]
        
        for pattern in claim_patterns:
            matches = re.finditer(pattern, content)
            for match in matches:
                # æª¢æŸ¥é™„è¿‘æ˜¯å¦æœ‰å¼•ç”¨
                surrounding_text = content[max(0, match.start()-50):match.end()+50]
                if not re.search(r'\[.*?\]|\(.*?\)|\d{4}', surrounding_text):
                    points.append(CritiquePoint(
                        aspect=CritiqueAspect.ACCURACY,
                        severity=0.6,
                        description=f"ç¼ºå°‘å¼•ç”¨ä¾†æº: {match.group()}",
                        suggestion="è«‹æ·»åŠ å¯é çš„å¼•ç”¨ä¾†æº",
                        evidence=match.group()
                    ))
        
        return points
    
    def _check_numerical_accuracy(self, content: str) -> List[CritiquePoint]:
        """æª¢æŸ¥æ•¸å­—æº–ç¢ºæ€§"""
        points = []
        
        # æŸ¥æ‰¾æ•¸å­—å’Œå–®ä½
        number_patterns = [
            r'\d+(\.\d+)?%',      # ç™¾åˆ†æ¯”
            r'\d+(\.\d+)?\s*è¬',   # è¬å–®ä½
            r'\d+(\.\d+)?\s*å„„',   # å„„å–®ä½
        ]
        
        for pattern in number_patterns:
            matches = re.finditer(pattern, content)
            for match in matches:
                number_str = match.group()
                # æª¢æŸ¥æ•¸å­—åˆç†æ€§
                if self._is_suspicious_number(number_str):
                    points.append(CritiquePoint(
                        aspect=CritiqueAspect.ACCURACY,
                        severity=0.4,
                        description=f"æ•¸å­—å¯èƒ½ä¸åˆç†: {number_str}",
                        suggestion="è«‹é©—è­‰æ•¸å­—çš„æº–ç¢ºæ€§å’Œåˆç†æ€§",
                        evidence=number_str
                    ))
        
        return points
    
    def _assess_fact_confidence(self, fact_statement: str, context: Dict[str, Any]) -> float:
        """è©•ä¼°äº‹å¯¦é™³è¿°çš„å¯ä¿¡åº¦"""
        # ç°¡åŒ–å¯¦ä½œï¼šåŸºæ–¼é—œéµè©è©•ä¼°
        high_confidence_indicators = ['æ ¹æ“šå®˜æ–¹', 'æ”¿åºœçµ±è¨ˆ', 'ç§‘å­¸ç ”ç©¶']
        low_confidence_indicators = ['æ“šèªª', 'æœ‰äººèªç‚º', 'å¯èƒ½']
        
        confidence = 0.5  # åŸºæº–ä¿¡å¿ƒåº¦
        
        for indicator in high_confidence_indicators:
            if indicator in fact_statement:
                confidence += 0.3
        
        for indicator in low_confidence_indicators:
            if indicator in fact_statement:
                confidence -= 0.3
        
        return max(0.0, min(1.0, confidence))
    
    def _is_suspicious_number(self, number_str: str) -> bool:
        """æª¢æŸ¥æ•¸å­—æ˜¯å¦å¯ç–‘"""
        # ç°¡åŒ–å¯¦ä½œï¼šæª¢æŸ¥æ˜¯å¦ç‚ºæ˜é¡¯ä¸åˆç†çš„æ•¸å­—
        if '%' in number_str:
            percentage = float(re.search(r'\d+(\.\d+)?', number_str).group())
            return percentage > 100 or percentage < 0
        
        return False
    
    def get_supported_aspects(self) -> List[CritiqueAspect]:
        return [CritiqueAspect.ACCURACY]


class CompletenessCritiqueStrategy(CritiqueStrategy):
    """å®Œæ•´æ€§æ‰¹è©•ç­–ç•¥"""
    
    def critique(self, content: str, context: Dict[str, Any]) -> List[CritiquePoint]:
        """æª¢æŸ¥å…§å®¹å®Œæ•´æ€§"""
        critique_points = []
        
        # æª¢æŸ¥çµæ§‹å®Œæ•´æ€§
        critique_points.extend(self._check_structural_completeness(content, context))
        
        # æª¢æŸ¥è«–é»è¦†è“‹åº¦
        critique_points.extend(self._check_argument_coverage(content, context))
        
        # æª¢æŸ¥å¿…è¦å…ƒç´ 
        critique_points.extend(self._check_required_elements(content, context))
        
        return critique_points
    
    def _check_structural_completeness(self, content: str, context: Dict[str, Any]) -> List[CritiquePoint]:
        """æª¢æŸ¥çµæ§‹å®Œæ•´æ€§"""
        points = []
        
        required_sections = context.get('required_sections', ['å¼•è¨€', 'ä¸»é«”', 'çµè«–'])
        content_type = context.get('content_type', 'general')
        
        if content_type == 'report':
            required_sections = ['æ‘˜è¦', 'å¼•è¨€', 'æ–¹æ³•', 'çµæœ', 'è¨è«–', 'çµè«–']
        elif content_type == 'analysis':
            required_sections = ['èƒŒæ™¯', 'åˆ†æ', 'ç™¼ç¾', 'å»ºè­°']
        
        for section in required_sections:
            if not self._has_section(content, section):
                points.append(CritiquePoint(
                    aspect=CritiqueAspect.COMPLETENESS,
                    severity=0.7,
                    description=f"ç¼ºå°‘å¿…è¦ç« ç¯€: {section}",
                    suggestion=f"è«‹æ·»åŠ  {section} ç« ç¯€",
                    evidence=f"æœªæ‰¾åˆ° {section} ç›¸é—œå…§å®¹"
                ))
        
        return points
    
    def _check_argument_coverage(self, content: str, context: Dict[str, Any]) -> List[CritiquePoint]:
        """æª¢æŸ¥è«–é»è¦†è“‹åº¦"""
        points = []
        
        expected_topics = context.get('expected_topics', [])
        covered_topics = self._extract_covered_topics(content)
        
        for topic in expected_topics:
            if topic not in covered_topics:
                points.append(CritiquePoint(
                    aspect=CritiqueAspect.COMPLETENESS,
                    severity=0.5,
                    description=f"æœªæ¶µè“‹é‡è¦ä¸»é¡Œ: {topic}",
                    suggestion=f"è«‹å¢åŠ é—œæ–¼ {topic} çš„è¨è«–",
                    evidence=f"å…§å®¹ä¸­æœªç™¼ç¾ {topic} ç›¸é—œè¨è«–"
                ))
        
        return points
    
    def _check_required_elements(self, content: str, context: Dict[str, Any]) -> List[CritiquePoint]:
        """æª¢æŸ¥å¿…è¦å…ƒç´ """
        points = []
        
        # æª¢æŸ¥é•·åº¦è¦æ±‚
        min_length = context.get('min_length', 0)
        if len(content) < min_length:
            points.append(CritiquePoint(
                aspect=CritiqueAspect.COMPLETENESS,
                severity=0.6,
                description=f"å…§å®¹é•·åº¦ä¸è¶³ (ç•¶å‰: {len(content)}, è¦æ±‚: {min_length})",
                suggestion="è«‹æ“´å……å…§å®¹ä»¥æ»¿è¶³é•·åº¦è¦æ±‚",
                evidence=f"å­—æ•¸: {len(content)}"
            ))
        
        # æª¢æŸ¥é—œéµè©å¯†åº¦
        required_keywords = context.get('required_keywords', [])
        for keyword in required_keywords:
            if keyword.lower() not in content.lower():
                points.append(CritiquePoint(
                    aspect=CritiqueAspect.COMPLETENESS,
                    severity=0.4,
                    description=f"ç¼ºå°‘é—œéµè©: {keyword}",
                    suggestion=f"è«‹åœ¨å…§å®¹ä¸­åŒ…å«é—œéµè© '{keyword}'",
                    evidence=f"æœªæ‰¾åˆ°é—œéµè© '{keyword}'"
                ))
        
        return points
    
    def _has_section(self, content: str, section_name: str) -> bool:
        """æª¢æŸ¥æ˜¯å¦åŒ…å«ç‰¹å®šç« ç¯€"""
        section_patterns = [
            f'{section_name}',
            f'## {section_name}',
            f'# {section_name}',
            f'{section_name}ï¼š',
            f'{section_name}:',
        ]
        
        for pattern in section_patterns:
            if pattern in content:
                return True
        
        return False
    
    def _extract_covered_topics(self, content: str) -> List[str]:
        """æå–å·²æ¶µè“‹çš„ä¸»é¡Œ"""
        # ç°¡åŒ–å¯¦ä½œï¼šåŸºæ–¼é—œéµè©æå–
        topics = []
        
        # é€™è£¡å¯ä»¥ä½¿ç”¨æ›´è¤‡é›œçš„ NLP æŠ€è¡“
        topic_keywords = {
            'technology': ['æŠ€è¡“', 'ç§‘æŠ€', 'å‰µæ–°'],
            'business': ['å•†æ¥­', 'ç‡Ÿæ”¶', 'å¸‚å ´'],
            'society': ['ç¤¾æœƒ', 'æ–‡åŒ–', 'äººç¾¤'],
            'environment': ['ç’°å¢ƒ', 'ç”Ÿæ…‹', 'æ°¸çºŒ'],
        }
        
        for topic, keywords in topic_keywords.items():
            if any(keyword in content for keyword in keywords):
                topics.append(topic)
        
        return topics
    
    def get_supported_aspects(self) -> List[CritiqueAspect]:
        return [CritiqueAspect.COMPLETENESS]


class ClarityCritiqueStrategy(CritiqueStrategy):
    """æ¸…æ™°åº¦æ‰¹è©•ç­–ç•¥"""
    
    def critique(self, content: str, context: Dict[str, Any]) -> List[CritiquePoint]:
        """æª¢æŸ¥å…§å®¹æ¸…æ™°åº¦"""
        critique_points = []
        
        # æª¢æŸ¥èªè¨€æ¸…æ™°åº¦
        critique_points.extend(self._check_language_clarity(content))
        
        # æª¢æŸ¥çµæ§‹æ¸…æ™°åº¦
        critique_points.extend(self._check_structural_clarity(content))
        
        # æª¢æŸ¥é‚è¼¯æ¸…æ™°åº¦
        critique_points.extend(self._check_logical_clarity(content))
        
        return critique_points
    
    def _check_language_clarity(self, content: str) -> List[CritiquePoint]:
        """æª¢æŸ¥èªè¨€æ¸…æ™°åº¦"""
        points = []
        
        # æª¢æŸ¥å¥å­é•·åº¦
        sentences = re.split(r'[ã€‚ï¼ï¼Ÿ]', content)
        for sentence in sentences:
            if len(sentence) > 100:  # éé•·çš„å¥å­
                points.append(CritiquePoint(
                    aspect=CritiqueAspect.CLARITY,
                    severity=0.4,
                    description="å¥å­éé•·ï¼Œå½±éŸ¿é–±è®€ç†è§£",
                    suggestion="å»ºè­°å°‡é•·å¥æ‹†åˆ†ç‚ºå¤šå€‹çŸ­å¥",
                    evidence=sentence[:50] + "..."
                ))
        
        # æª¢æŸ¥å°ˆæ¥­è¡“èª
        jargon_patterns = [
            r'\b[A-Z]{3,}\b',  # å…¨å¤§å¯«ç¸®å¯«
            r'\b\w*(?:tion|ment|ness|ity)\b',  # è¤‡é›œè©å½™
        ]
        
        jargon_count = 0
        for pattern in jargon_patterns:
            jargon_count += len(re.findall(pattern, content))
        
        jargon_density = jargon_count / max(len(content.split()), 1)
        if jargon_density > 0.1:  # å°ˆæ¥­è¡“èªå¯†åº¦éé«˜
            points.append(CritiquePoint(
                aspect=CritiqueAspect.CLARITY,
                severity=0.5,
                description="å°ˆæ¥­è¡“èªéå¤šï¼Œå¯èƒ½å½±éŸ¿ç†è§£",
                suggestion="å»ºè­°è§£é‡‹å°ˆæ¥­è¡“èªæˆ–ä½¿ç”¨æ›´é€šä¿—çš„è¡¨é”",
                evidence=f"å°ˆæ¥­è¡“èªå¯†åº¦: {jargon_density:.2%}"
            ))
        
        return points
    
    def _check_structural_clarity(self, content: str) -> List[CritiquePoint]:
        """æª¢æŸ¥çµæ§‹æ¸…æ™°åº¦"""
        points = []
        
        # æª¢æŸ¥æ®µè½çµæ§‹
        paragraphs = content.split('\n\n')
        
        # æª¢æŸ¥æ®µè½é•·åº¦
        for i, paragraph in enumerate(paragraphs):
            if len(paragraph) > 500:  # æ®µè½éé•·
                points.append(CritiquePoint(
                    aspect=CritiqueAspect.CLARITY,
                    severity=0.3,
                    description=f"ç¬¬ {i+1} æ®µéé•·",
                    suggestion="å»ºè­°å°‡é•·æ®µè½æ‹†åˆ†ä»¥æé«˜å¯è®€æ€§",
                    evidence=paragraph[:100] + "..."
                ))
        
        # æª¢æŸ¥æ¨™é¡Œçµæ§‹
        headings = re.findall(r'^#+\s+.+$', content, re.MULTILINE)
        if len(paragraphs) > 5 and len(headings) == 0:
            points.append(CritiquePoint(
                aspect=CritiqueAspect.CLARITY,
                severity=0.6,
                description="ç¼ºå°‘ç« ç¯€æ¨™é¡Œï¼Œçµæ§‹ä¸æ¸…æ™°",
                suggestion="è«‹æ·»åŠ é©ç•¶çš„ç« ç¯€æ¨™é¡Œä¾†çµ„ç¹”å…§å®¹",
                evidence=f"å…§å®¹æœ‰ {len(paragraphs)} æ®µä½†ç„¡æ¨™é¡Œ"
            ))
        
        return points
    
    def _check_logical_clarity(self, content: str) -> List[CritiquePoint]:
        """æª¢æŸ¥é‚è¼¯æ¸…æ™°åº¦"""
        points = []
        
        # æª¢æŸ¥é‚è¼¯é€£æ¥è©
        logical_connectors = ['å› æ­¤', 'æ‰€ä»¥', 'ç„¶è€Œ', 'ä½†æ˜¯', 'æ­¤å¤–', 'é¦–å…ˆ', 'å…¶æ¬¡', 'æœ€å¾Œ']
        connector_count = sum(content.count(connector) for connector in logical_connectors)
        
        paragraphs = content.split('\n\n')
        connector_density = connector_count / max(len(paragraphs), 1)
        
        if connector_density < 0.5:  # é‚è¼¯é€£æ¥è©ä¸è¶³
            points.append(CritiquePoint(
                aspect=CritiqueAspect.CLARITY,
                severity=0.4,
                description="é‚è¼¯é€£æ¥è©ä¸è¶³ï¼Œæ®µè½é–“ç¼ºä¹éŠœæ¥",
                suggestion="è«‹æ·»åŠ é©ç•¶çš„é‚è¼¯é€£æ¥è©ä»¥æ”¹å–„æ–‡ç« æµæš¢åº¦",
                evidence=f"é‚è¼¯é€£æ¥è©å¯†åº¦: {connector_density:.2f}"
            ))
        
        return points
    
    def get_supported_aspects(self) -> List[CritiqueAspect]:
        return [CritiqueAspect.CLARITY]


class SelfCritiqueEngine:
    """è‡ªæˆ‘æ‰¹è©•å¼•æ“"""
    
    def __init__(self):
        self.strategies: Dict[CritiqueAspect, CritiqueStrategy] = {
            CritiqueAspect.ACCURACY: AccuracyCritiqueStrategy(),
            CritiqueAspect.COMPLETENESS: CompletenessCritiqueStrategy(),
            CritiqueAspect.CLARITY: ClarityCritiqueStrategy(),
        }
        
        # è©•åˆ†æ¬Šé‡
        self.aspect_weights = {
            CritiqueAspect.ACCURACY: 0.3,
            CritiqueAspect.COMPLETENESS: 0.25,
            CritiqueAspect.CLARITY: 0.2,
            CritiqueAspect.RELEVANCE: 0.15,
            CritiqueAspect.COHERENCE: 0.1,
        }
    
    def critique(self, content: str, context: Dict[str, Any] = None, 
                aspects: List[CritiqueAspect] = None,
                reflection_level: ReflectionLevel = ReflectionLevel.STRUCTURAL) -> ReflectionResult:
        """åŸ·è¡Œå…¨é¢æ‰¹è©•åˆ†æ"""
        if context is None:
            context = {}
        
        if aspects is None:
            aspects = list(self.strategies.keys())
        
        import time
        start_time = time.time()
        
        # æ”¶é›†æ‰€æœ‰æ‰¹è©•è¦é»
        all_critique_points = []
        
        for aspect in aspects:
            if aspect in self.strategies:
                try:
                    points = self.strategies[aspect].critique(content, context)
                    all_critique_points.extend(points)
                except Exception as e:
                    # è¨˜éŒ„ç­–ç•¥åŸ·è¡ŒéŒ¯èª¤
                    all_critique_points.append(CritiquePoint(
                        aspect=aspect,
                        severity=0.3,
                        description=f"æ‰¹è©•åˆ†æå‡ºéŒ¯: {str(e)}",
                        suggestion="è«‹æª¢æŸ¥å…§å®¹æ ¼å¼æˆ–è¯ç¹«ç³»çµ±ç®¡ç†å“¡",
                        evidence=str(e)
                    ))
        
        # è¨ˆç®—æ•´é«”è©•åˆ†
        overall_score = self._calculate_overall_score(all_critique_points, aspects)
        
        # ç”Ÿæˆæ”¹é€²å»ºè­°
        improvement_suggestions = self._generate_improvement_suggestions(all_critique_points)
        
        reflection_time = time.time() - start_time
        
        return ReflectionResult(
            original_content=content,
            critique_points=all_critique_points,
            overall_score=overall_score,
            reflection_level=reflection_level,
            improvement_suggestions=improvement_suggestions,
            reflection_time=reflection_time,
            iteration_count=1
        )
    
    def _calculate_overall_score(self, critique_points: List[CritiquePoint], 
                               aspects: List[CritiqueAspect]) -> float:
        """è¨ˆç®—æ•´é«”è©•åˆ†"""
        if not aspects:
            return 1.0
        
        aspect_scores = {}
        
        # è¨ˆç®—æ¯å€‹ç¶­åº¦çš„å¾—åˆ†
        for aspect in aspects:
            aspect_points = [p for p in critique_points if p.aspect == aspect]
            
            if not aspect_points:
                aspect_scores[aspect] = 1.0  # æ²’æœ‰å•é¡Œ = æ»¿åˆ†
            else:
                # åŸºæ–¼å•é¡Œåš´é‡ç¨‹åº¦è¨ˆç®—å¾—åˆ†
                total_penalty = sum(point.severity for point in aspect_points)
                max_penalty = len(aspect_points)  # å‡è¨­æ¯å€‹å•é¡Œæœ€å¤šæ‰£1åˆ†
                aspect_scores[aspect] = max(0.0, 1.0 - (total_penalty / max_penalty))
        
        # åŠ æ¬Šå¹³å‡
        weighted_score = 0.0
        total_weight = 0.0
        
        for aspect, score in aspect_scores.items():
            weight = self.aspect_weights.get(aspect, 0.1)
            weighted_score += score * weight
            total_weight += weight
        
        return weighted_score / max(total_weight, 1.0)
    
    def _generate_improvement_suggestions(self, critique_points: List[CritiquePoint]) -> List[str]:
        """ç”Ÿæˆæ”¹é€²å»ºè­°"""
        suggestions = []
        
        # æŒ‰åš´é‡ç¨‹åº¦æ’åº
        sorted_points = sorted(critique_points, key=lambda p: p.severity, reverse=True)
        
        # å„ªå…ˆè™•ç†åš´é‡å•é¡Œ
        critical_points = [p for p in sorted_points if p.is_critical]
        major_points = [p for p in sorted_points if p.is_major and not p.is_critical]
        
        if critical_points:
            suggestions.append("ğŸš¨ å„ªå…ˆè™•ç†é—œéµå•é¡Œ:")
            for point in critical_points[:3]:  # æœ€å¤šé¡¯ç¤º3å€‹
                suggestions.append(f"   â€¢ {point.suggestion}")
        
        if major_points:
            suggestions.append("âš ï¸  é‡è¦æ”¹é€²å»ºè­°:")
            for point in major_points[:3]:  # æœ€å¤šé¡¯ç¤º3å€‹
                suggestions.append(f"   â€¢ {point.suggestion}")
        
        # æŒ‰ç¶­åº¦åˆ†çµ„çš„å»ºè­°
        aspect_suggestions = {}
        for point in sorted_points:
            if point.aspect not in aspect_suggestions:
                aspect_suggestions[point.aspect] = []
            if len(aspect_suggestions[point.aspect]) < 2:  # æ¯å€‹ç¶­åº¦æœ€å¤š2å€‹å»ºè­°
                aspect_suggestions[point.aspect].append(point.suggestion)
        
        if len(aspect_suggestions) > 1:
            suggestions.append("ğŸ“‹ åˆ†é¡æ”¹é€²å»ºè­°:")
            for aspect, asp_suggestions in aspect_suggestions.items():
                suggestions.append(f"   {aspect.value}:")
                for suggestion in asp_suggestions:
                    suggestions.append(f"     - {suggestion}")
        
        return suggestions


class ReflectiveAgent(BaseAgent):
    """å…·å‚™åæ€èƒ½åŠ›çš„ Agent"""
    
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.critique_engine = SelfCritiqueEngine()
        self.max_reflection_iterations = 3
        self.quality_threshold = 0.7
        
        # åæ€æ­·å²
        self.reflection_history: List[ReflectionResult] = []
    
    def execute_with_reflection(self, task_description: str, 
                              reflection_context: Dict[str, Any] = None) -> Dict[str, Any]:
        """å¸¶åæ€çš„ä»»å‹™åŸ·è¡Œ"""
        if reflection_context is None:
            reflection_context = {}
        
        # åˆå§‹åŸ·è¡Œ
        initial_result = self.execute(task_description)
        current_content = str(initial_result)
        
        # åæ€è¿­ä»£
        iteration = 0
        while iteration < self.max_reflection_iterations:
            # åŸ·è¡Œåæ€åˆ†æ
            reflection_result = self.critique_engine.critique(
                content=current_content,
                context=reflection_context,
                reflection_level=ReflectionLevel.STRUCTURAL
            )
            
            reflection_result.iteration_count = iteration + 1
            self.reflection_history.append(reflection_result)
            
            # æª¢æŸ¥æ˜¯å¦éœ€è¦æ”¹é€²
            if not reflection_result.needs_revision:
                break
            
            # åŸºæ–¼åæ€çµæœæ”¹é€²å…§å®¹
            improved_content = self._improve_based_on_reflection(
                current_content, reflection_result
            )
            
            if improved_content == current_content:
                # ç„¡æ³•é€²ä¸€æ­¥æ”¹é€²
                break
            
            current_content = improved_content
            iteration += 1
        
        # è¿”å›æœ€çµ‚çµæœ
        final_reflection = self.reflection_history[-1] if self.reflection_history else None
        
        return {
            "final_result": current_content,
            "reflection_summary": self._create_reflection_summary(final_reflection),
            "iterations": iteration + 1,
            "improvement_achieved": len(self.reflection_history) > 1,
            "quality_score": final_reflection.overall_score if final_reflection else 0.0
        }
    
    def _improve_based_on_reflection(self, content: str, 
                                   reflection: ReflectionResult) -> str:
        """åŸºæ–¼åæ€çµæœæ”¹é€²å…§å®¹"""
        # é€™è£¡å¯ä»¥æ•´åˆ LLM ä¾†å¯¦éš›æ”¹é€²å…§å®¹
        # ç•¶å‰å¯¦ä½œè¿”å›æ”¹é€²æç¤º
        
        improvement_prompt = f"""
è«‹æ ¹æ“šä»¥ä¸‹åæ€åˆ†ææ”¹é€²å…§å®¹:

åŸå§‹å…§å®¹:
{content}

ä¸»è¦å•é¡Œ:
{chr(10).join(f"â€¢ {point.description}: {point.suggestion}" for point in reflection.critique_points if point.is_major or point.is_critical)}

æ”¹é€²å»ºè­°:
{chr(10).join(reflection.improvement_suggestions)}

è«‹æä¾›æ”¹é€²å¾Œçš„å…§å®¹ï¼Œç¢ºä¿è§£æ±ºä¸Šè¿°å•é¡Œã€‚
"""
        
        # å¯¦éš›æ‡‰ç”¨ä¸­ï¼Œé€™è£¡æœƒèª¿ç”¨ LLM ç”Ÿæˆæ”¹é€²å…§å®¹
        # æš«æ™‚è¿”å›å¸¶æœ‰æ”¹é€²æç¤ºçš„å…§å®¹
        return f"{content}\n\n[æ”¹é€²æç¤º: {reflection.improvement_suggestions[0] if reflection.improvement_suggestions else 'ç„¡å…·é«”å»ºè­°'}]"
    
    def _create_reflection_summary(self, reflection: Optional[ReflectionResult]) -> Dict[str, Any]:
        """å‰µå»ºåæ€æ‘˜è¦"""
        if not reflection:
            return {"status": "no_reflection"}
        
        return {
            "quality_score": reflection.overall_score,
            "critical_issues": reflection.critical_issues_count,
            "major_issues": reflection.major_issues_count,
            "improvement_suggestions": reflection.improvement_suggestions,
            "reflection_time": reflection.reflection_time,
            "needs_revision": reflection.needs_revision
        }


# ä½¿ç”¨ç¯„ä¾‹
if __name__ == "__main__":
    # å‰µå»ºæ‰¹è©•å¼•æ“
    critique_engine = SelfCritiqueEngine()
    
    # æ¸¬è©¦å…§å®¹
    test_content = """
äººå·¥æ™ºæ…§ç™¼å±•è¿…é€Ÿã€‚å®ƒæ”¹è®Šäº†å¾ˆå¤šè¡Œæ¥­ã€‚AIæŠ€è¡“åŒ…æ‹¬æ©Ÿå™¨å­¸ç¿’ã€æ·±åº¦å­¸ç¿’ã€è‡ªç„¶èªè¨€è™•ç†ç­‰ã€‚
é€™äº›æŠ€è¡“åœ¨é†«ç™‚ã€é‡‘èã€æ•™è‚²ç­‰é ˜åŸŸéƒ½æœ‰æ‡‰ç”¨ã€‚æœªä¾†AIæœƒæ›´åŠ æ™®åŠã€‚
ä½†ä¹Ÿéœ€è¦æ³¨æ„AIçš„å€«ç†å•é¡Œå’Œæ½›åœ¨é¢¨éšªã€‚
"""
    
    # åŸ·è¡Œæ‰¹è©•åˆ†æ
    result = critique_engine.critique(
        content=test_content,
        context={
            "content_type": "analysis",
            "min_length": 200,
            "required_keywords": ["æ©Ÿå™¨å­¸ç¿’", "æ‡‰ç”¨å ´æ™¯"],
            "expected_topics": ["technology", "society"]
        },
        aspects=[CritiqueAspect.ACCURACY, CritiqueAspect.COMPLETENESS, CritiqueAspect.CLARITY]
    )
    
    print("=== åæ€åˆ†æçµæœ ===")
    print(f"æ•´é«”è©•åˆ†: {result.overall_score:.2f}")
    print(f"æ˜¯å¦éœ€è¦ä¿®è¨‚: {result.needs_revision}")
    print(f"åæ€æ™‚é–“: {result.reflection_time:.3f}ç§’")
    
    print("\n=== ç™¼ç¾çš„å•é¡Œ ===")
    for point in result.critique_points:
        severity_icon = "ğŸš¨" if point.is_critical else "âš ï¸" if point.is_major else "ğŸ’¡"
        print(f"{severity_icon} [{point.aspect.value}] {point.description}")
        print(f"   å»ºè­°: {point.suggestion}")
        if point.evidence:
            print(f"   è­‰æ“š: {point.evidence}")
        print()
    
    print("=== æ”¹é€²å»ºè­° ===")
    for suggestion in result.improvement_suggestions:
        print(suggestion) 